{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a576faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcae2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring size of img, batch size, epochs and file paths. Dataset can be downloaded from here: https://www.kaggle.com/grassknoted/asl-alphabet\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "train_path = '../dataset/asl_alphabet_train/asl_alphabet_train'\n",
    "\n",
    "test_path = '../dataset/asl_alphabet_test/asl_alphabet_test'\n",
    "\n",
    "cp_path = '../model/Checkpoints'\n",
    "\n",
    "model_path = '../model/asl_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43befbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to randomly change zoom, and position of and generate tensor image data of training photo to allow for training with a more varied dataset\n",
    "augment_train_data = ImageDataGenerator(horizontal_flip=True,\n",
    "                                        rotation_range=50,\n",
    "                                        zoom_range=0.2,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        rescale=1./255,\n",
    "                                        validation_split=0.1)\n",
    "                                        \n",
    "# Function to rescale test data and return tensor image data of test photo\n",
    "augment_test_data = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0afc9c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87000 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "# Flipping and zooming train data\n",
    "train_dataset = augment_train_data.flow_from_directory(train_path,\n",
    "                                                       shuffle=True,\n",
    "                                                       classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "                                                                'L', 'M', 'N',\n",
    "                                                                'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y',\n",
    "                                                                'Z', 'space',\n",
    "                                                                'del', 'nothing'],\n",
    "                                                       target_size=(\n",
    "                                                           img_size, img_size),\n",
    "                                                       batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e963f7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "# Rescaling of test data\n",
    "test_dataset = augment_train_data.flow_from_directory(test_path,\n",
    "                                                      classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "                                                               'L', 'M', 'N',\n",
    "                                                               'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y',\n",
    "                                                               'Z', 'space', 'del', 'nothing'],\n",
    "                                                      target_size=(\n",
    "                                                          img_size, img_size),\n",
    "                                                      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "543de3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a sequential model (1 input and 1 output tensor) using pre-trained model from tensorflow hub\n",
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "\n",
    "download_model = hub.KerasLayer(url,input_shape=(img_size,img_size,3))\n",
    "\n",
    "model = Sequential([\n",
    "    download_model,\n",
    "    Dense(29),\n",
    "    Activation(\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c04cff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84bf9ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model summary: \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1001)              3540265   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 29)                29058     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 29)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,569,323\n",
      "Trainable params: 29,058\n",
      "Non-trainable params: 3,540,265\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " Model Training: \n",
      "Epoch 1/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8366WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 613s 225ms/step - loss: 0.5248 - accuracy: 0.8366\n",
      "Epoch 2/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.8466WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 613s 225ms/step - loss: 0.4932 - accuracy: 0.8466\n",
      "Epoch 3/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.8546WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 623s 229ms/step - loss: 0.4662 - accuracy: 0.8546\n",
      "Epoch 4/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.8610WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 628s 231ms/step - loss: 0.4513 - accuracy: 0.8610\n",
      "Epoch 5/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8645WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 608s 223ms/step - loss: 0.4373 - accuracy: 0.8645\n",
      "Epoch 6/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.8650WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 613s 226ms/step - loss: 0.4369 - accuracy: 0.8650\n",
      "Epoch 7/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.8666WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 610s 224ms/step - loss: 0.4334 - accuracy: 0.8666\n",
      "Epoch 8/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8694WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 610s 224ms/step - loss: 0.4237 - accuracy: 0.8694\n",
      "Epoch 9/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.8737WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719/2719 [==============================] - 618s 227ms/step - loss: 0.4111 - accuracy: 0.8737\n",
      "Epoch 10/10\n",
      "2719/2719 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8738WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "2719/2719 [==============================] - 610s 224ms/step - loss: 0.4161 - accuracy: 0.8738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16481804220>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary of model and train model with train dataset\n",
    "print(\"\\n Model summary: \")\n",
    "print(model.summary())\n",
    "\n",
    "print(\"\\n Model Training: \")\n",
    "model.fit(train_dataset,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b979be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load Model for testing \n",
    "# Only run if you are testing an already saved model\n",
    "model = tf.keras.models.load_model('../model/asl_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f74d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Evaluation: \n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1736 - accuracy: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1735614389181137, 0.9285714030265808]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model using test dataset\n",
    "print(\"\\n Model Evaluation: \")\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75f53991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/asl_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/asl_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save trained model\n",
    "model.save(\"../model/asl_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
